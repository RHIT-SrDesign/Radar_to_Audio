{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Turn this into a .py file so that the client can run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 10:29:45.376348: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 10:29:45.376392: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 10:29:45.378390: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 10:29:45.552460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be a good neighbor. Let other people use the GPU too. \n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the training data\n",
    "data_file_location = 'training_data/'\n",
    "data_file_name = 'data03_train.npy'\n",
    "label_file_name = 'labels03_train.npy'\n",
    "\n",
    "checkpoint_filepath = 'temp/checkpoint/convnet03_2500.h5'\n",
    "log_filepath = 'temp/tb_logs'\n",
    "\n",
    "data = np.load(data_file_location+data_file_name)\n",
    "labels = np.load(data_file_location+label_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data\n",
    "y = labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape,output_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(10, kernel_size=5, padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(20, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(30, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(40, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(50, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(60, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(70, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(80, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Conv1D(90, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_model(input_shape, output_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(1, kernel_size=3, padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 10:29:50.857413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:50.897043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:50.897085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:50.900524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:50.900565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:50.900588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:53.091538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:53.091584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:53.091593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-12 10:29:53.091623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-12 10:29:53.091640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2074 MB memory:  -> device: 0, name: Quadro T1000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1024, 10)          410       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 512, 10)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 512, 20)           1020      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 256, 20)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 256, 30)           3030      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 128, 30)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 128, 40)           6040      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 64, 40)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 64, 50)            10050     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 32, 50)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 32, 60)            9060      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 16, 60)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 16, 70)            12670     \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 8, 70)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 8, 80)             16880     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 4, 80)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 4, 90)             21690     \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 2, 90)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 180)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               36200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                5025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122075 (476.86 KB)\n",
      "Trainable params: 122075 (476.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape=(1024,8),output_size=25)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the callbacks\n",
    "checkpt = ModelCheckpoint(checkpoint_filepath, save_best_only=True, verbose=0)\n",
    "tb = TensorBoard(log_dir=log_filepath)\n",
    "e_stop = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 10:29:58.363499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-12-12 10:30:01.612890: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff35d1870c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-12 10:30:01.612939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro T1000, Compute Capability 7.5\n",
      "2023-12-12 10:30:01.626324: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-12 10:30:01.762261: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/thomas/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 12s - loss: 3.2240 - accuracy: 0.0550 - val_loss: 3.2111 - val_accuracy: 0.0400 - 12s/epoch - 6s/step\n",
      "Epoch 2/100\n",
      "2/2 - 0s - loss: 3.2086 - accuracy: 0.0550 - val_loss: 3.2268 - val_accuracy: 0.0600 - 100ms/epoch - 50ms/step\n",
      "Epoch 3/100\n",
      "2/2 - 0s - loss: 3.1986 - accuracy: 0.0600 - val_loss: 3.2433 - val_accuracy: 0.0600 - 102ms/epoch - 51ms/step\n",
      "Epoch 4/100\n",
      "2/2 - 0s - loss: 3.1861 - accuracy: 0.0650 - val_loss: 3.2701 - val_accuracy: 0.0600 - 86ms/epoch - 43ms/step\n",
      "Epoch 5/100\n",
      "2/2 - 0s - loss: 3.1847 - accuracy: 0.0650 - val_loss: 3.2830 - val_accuracy: 0.0600 - 93ms/epoch - 47ms/step\n",
      "Epoch 6/100\n",
      "2/2 - 0s - loss: 3.1772 - accuracy: 0.0700 - val_loss: 3.2617 - val_accuracy: 0.0600 - 110ms/epoch - 55ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "hist = model.fit(x, y, epochs=100, validation_split=0.2, verbose=2, batch_size=100,\n",
    "                 callbacks=[checkpt, tb, e_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
